{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cccac8a-bf4a-48c0-b501-563e44df5c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow for Production AI and ML\n",
    "\n",
    "## The Scenario\n",
    "\n",
    "üõ©Ô∏è **Leadership just gave you the order:** Your team has IoT sensor data streaming in from aircraft engines across 5 factories. By the end of the week, you need to deploy a predictive model to identify potential defects before they cause failures. This notebook gets you from raw data to a production-ready model in 30 minutes.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "‚úÖ **Experiment** - Track model training with MLflow autologging  \n",
    "‚úÖ **Register** - Version control models in Unity Catalog  \n",
    "‚úÖ **Compare** - Train multiple models and compare results  \n",
    "\n",
    "**Key Concepts:**\n",
    "- **MLflow Tracking**: Automatically log parameters, metrics, and models\n",
    "- **Unity Catalog Model Registry**: Enterprise-grade model versioning and governance\n",
    "- **Model Aliases**: Tag models as \"Champion\" or \"Challenger\" for deployment\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- [MLflow Tracking](https://docs.databricks.com/aws/en/mlflow/tracking)\n",
    "- [Databricks Autologging](https://docs.databricks.com/aws/en/mlflow/databricks-autologging)\n",
    "- [Unity Catalog Model Registry](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c483f8e9-6598-487a-9f8d-490586696bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Why MLflow?\n",
    "\n",
    "Without MLflow, data scientists face challenges like:\n",
    "- **Lost experiments** - \"Which hyperparameters gave us that 95% accuracy?\"\n",
    "- **Model chaos** - \"Where's the model we deployed last week?\"\n",
    "- **No reproducibility** - \"I can't recreate these results\"\n",
    "\n",
    "MLflow solves this by providing:\n",
    "- **Experiment Tracking**: Automatic logging of parameters, metrics, and artifacts\n",
    "- **Model Registry**: Centralized model versioning with Unity Catalog\n",
    "- **Deployment**: Seamless path from experiment to production\n",
    "\n",
    "**The MLOps Workflow (This Notebook):**\n",
    "```\n",
    "1. EXPERIMENT ‚Üí Train models, MLflow tracks everything\n",
    "2. REGISTER   ‚Üí Save best model to Unity Catalog\n",
    "3. COMPARE    ‚Üí Review experiments and pick the best\n",
    "\n",
    "(Next notebook covers: DEPLOY ‚Üí Inference patterns)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683435ca-8f01-48cf-a548-97a445557694",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow scikit-learn \n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "131e1af4-b4f5-45b7-8f44-b746b186425b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup: Configuration\n",
    "\n",
    "Update these values with your catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc3776c-4e7d-41af-aa4f-bfcec4ed085e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import re\n",
    "\n",
    "catalog = \"dwx_airops_insights_platform_dev_working\"\n",
    "source_schema = \"db_crash_course\"  # Shared schema to read from\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "username_base = username.split('@')[0]  # Extract username before @ symbol\n",
    "target_schema = re.sub(r'[^a-zA-Z0-9_]', '_', username_base)  # Replace special chars with _\n",
    "\n",
    "# Create target schema if it doesn't exist\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{target_schema}\")\n",
    "\n",
    "print(f\"‚úÖ Using catalog: {catalog}\")\n",
    "print(f\"üìñ Reading from schema: {source_schema} (shared)\")\n",
    "print(f\"‚úçÔ∏è  Writing to schema: {target_schema} (your personal schema)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "321a4991-5f2b-43dc-a492-0971325b4c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## AutoML vs MLflow in Notebooks: What's the Difference?\n",
    "\n",
    "In the previous notebook, you used **AutoML** - Databricks' point-and-click UI for training models. In this notebook, you'll use **MLflow** within notebooks for custom model training.\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "| Aspect | AutoML (Previous Notebook) | MLflow in Notebooks (This Notebook) |\n",
    "|--------|---------------------------|-------------------------------------|\n",
    "| **Interface** | Point-and-click UI | Code in notebooks |\n",
    "| **Control** | Automated decisions | Full control over everything |\n",
    "| **Speed** | Fast, no code needed | Requires writing code |\n",
    "| **Customization** | Limited to provided options | Unlimited customization |\n",
    "| **Best For** | Quick experiments, baselines | Custom models, fine-tuning |\n",
    "\n",
    "### Both Use MLflow Under the Hood!\n",
    "\n",
    "**Important:** AutoML automatically uses MLflow to track experiments. Whether you use AutoML or write custom code, **all experiments are tracked in MLflow**.\n",
    "\n",
    "**When to use which:**\n",
    "- **AutoML**: Fast proof-of-concept, baseline models, learning\n",
    "- **MLflow in Notebooks**: Custom algorithms, specific architectures, production models\n",
    "\n",
    "---\n",
    "\n",
    "## Load and Prepare Training Data\n",
    "\n",
    "Let's jump straight into preparing data for model training. You can explore tables in Catalog Explorer as you learned in Day 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "850c8844-8c7f-4449-a5aa-568dd7f59e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load sensor and inspection data from source schema (shared)\n",
    "sensor_df = spark.table(f\"{catalog}.{source_schema}.sensor_bronze\")\n",
    "inspection_df = spark.table(f\"{catalog}.{source_schema}.inspection_bronze\")\n",
    "\n",
    "# Join sensor data with inspection labels\n",
    "# For each device, take the most recent sensor reading before each inspection\n",
    "window_spec = Window.partitionBy(\"device_id\").orderBy(F.col(\"sensor_timestamp\").desc())\n",
    "\n",
    "training_data = (\n",
    "    sensor_df\n",
    "    .withColumnRenamed(\"timestamp\", \"sensor_timestamp\")\n",
    "    .join(\n",
    "        inspection_df.withColumnRenamed(\"timestamp\", \"inspection_timestamp\"),\n",
    "        [\"device_id\"]\n",
    "    )\n",
    "    .filter(F.col(\"sensor_timestamp\") <= F.col(\"inspection_timestamp\"))\n",
    "    .withColumn(\"row_num\", F.row_number().over(window_spec))\n",
    "    .filter(F.col(\"row_num\") == 1)\n",
    "    .select(\n",
    "        \"device_id\",\n",
    "        \"factory_id\", \n",
    "        \"model_id\",\n",
    "        \"airflow_rate\",\n",
    "        \"rotation_speed\",\n",
    "        \"air_pressure\",\n",
    "        \"temperature\",\n",
    "        \"delay\",\n",
    "        \"density\",\n",
    "        F.col(\"defect\").cast(\"int\").alias(\"defect\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {training_data.count():,} records\")\n",
    "print(f\"Defect rate: {training_data.filter('defect = 1').count() / training_data.count() * 100:.2f}%\")\n",
    "\n",
    "display(training_data.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af935d9-ba96-4fca-91fe-239e8d1a727e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Convert to Pandas for Sklearn\n",
    "\n",
    "For this quick example, we'll use scikit-learn. For larger datasets, consider using Spark MLlib or distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a67e94-7e4f-496c-bc01-59099b9e3241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to Pandas\n",
    "pdf = training_data.toPandas()\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [\"airflow_rate\", \"rotation_speed\", \"air_pressure\", \"temperature\", \"delay\", \"density\"]\n",
    "X = pdf[feature_cols]\n",
    "y = pdf[\"defect\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c15373-deea-44ca-91aa-8411b4b25f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1Ô∏è‚É£ EXPERIMENT: Train Model with MLflow Autologging\n",
    "\n",
    "**Key Point:** Use `mlflow.autolog()` to automatically track everything! No need to manually log parameters, metrics, or models.\n",
    "\n",
    "**What gets auto-logged:**\n",
    "- Model architecture and parameters\n",
    "- Training metrics (accuracy, precision, recall, etc.)\n",
    "- Model artifacts\n",
    "- Feature importances\n",
    "- Training dataset signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51420ad-acef-44e6-a517-d5f659874f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Enable autologging - this is the magic! ‚ú®\n",
    "mlflow.autolog()\n",
    "\n",
    "# Train model - MLflow automatically tracks everything\n",
    "with mlflow.start_run(run_name=\"IoT Defect Prediction - RF\") as run:\n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate additional metrics (autolog captures most, but we can add custom ones)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c29951c-bc75-4fdc-85e3-1b1dfaac3a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üîç Explore the Databricks MLflow UI\n",
    "\n",
    "**Click the \"Experiment\" button at the top right of this notebook** to open the MLflow UI. You'll see:\n",
    "\n",
    "1. **Runs table** - All your experiments in one place\n",
    "2. **Parameters** - Hyperparameters used (n_estimators, max_depth, etc.)\n",
    "3. **Metrics** - Model performance (accuracy, precision, recall, etc.)\n",
    "4. **Artifacts** - Saved model files, feature importances, and more\n",
    "5. **Charts** - Visualize metric comparisons across runs\n",
    "\n",
    "Try clicking on your run to see all the details that were automatically logged!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54b3bfa0-956e-4d25-92ea-dd0db4a6e0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train Another Model to Compare\n",
    "\n",
    "Let's train a Gradient Boosting model to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ade0bef-a8aa-460b-b207-c6c0f43d07f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values in temperature column\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Autologging is still enabled from earlier\n",
    "with mlflow.start_run(run_name=\"IoT Defect Prediction - GBM\") as run:\n",
    "    # Train Gradient Boosting\n",
    "    gbm_model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    gbm_model.fit(X_train_imputed, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = gbm_model.predict(X_test_imputed)\n",
    "    y_pred_proba = gbm_model.predict_proba(X_test_imputed)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"‚úÖ Run ID: {run.info.run_id}\")\n",
    "    print(f\"üìä Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"üéØ Precision: {precision:.4f}\")\n",
    "    print(f\"üîç Recall: {recall:.4f}\")\n",
    "    print(f\"üìà F1 Score: {f1:.4f}\")\n",
    "    print(f\"üìâ AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4707965c-109e-4507-94b4-fbacae849e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üí° **Pro Tip:** Go back to the MLflow UI and compare the two runs side-by-side. Which model performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa543e08-e7ba-4b85-8ec7-4ca3d4c3230a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2Ô∏è‚É£ REGISTER: Save Model to Unity Catalog\n",
    "\n",
    "The **Unity Catalog Model Registry** is your enterprise model store. It provides:\n",
    "- **Versioning**: Every model update creates a new version\n",
    "- **Lineage**: Track which data and code produced each model\n",
    "- **Governance**: Control who can access and deploy models\n",
    "- **Aliases**: Tag models as \"Champion\", \"Challenger\", \"Staging\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e1c6dc-7d13-4410-9682-8f0d0c71c560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the best model to your target schema\n",
    "# Model is unique because it's in your personal schema\n",
    "model_name = f\"{catalog}.{target_schema}.iot_defect_predictor\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "print(f\"üì¶ Registering model: {model_name}\")\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "print(f\"‚úÖ Registered model version: {model_details.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7d2954-56de-401c-8801-dd68853b1459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set Model Alias to \"Champion\"\n",
    "\n",
    "Model aliases let you tag specific versions for deployment (e.g., \"Champion\" for production, \"Challenger\" for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e543ab55-9d51-4906-a1c5-d98e7171bcce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Add model description\n",
    "client.update_registered_model(\n",
    "    name=model_name,\n",
    "    description=\"Random Forest model to predict defects in aircraft engine IoT sensors. Trained on sensor readings (airflow, rotation speed, temperature, pressure) and inspection results.\"\n",
    ")\n",
    "\n",
    "# Set the \"Champion\" alias to this version\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"Champion\",\n",
    "    version=model_details.version\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model version {model_details.version} tagged as 'Champion'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c3543f-3e25-42bb-9335-71ea7d148cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üéØ **View your model in Unity Catalog:**\n",
    "1. Click \"Catalog\" in the left sidebar\n",
    "2. Navigate to your catalog ‚Üí schema ‚Üí \"iot_defect_predictor\"\n",
    "3. See model versions, lineage, and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ee54fe-51df-49f9-bd6c-bad2c9600338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3Ô∏è‚É£ PREDICT: Load and Use the Model\n",
    "\n",
    "Load the \"Champion\" model and use it for predictions. This is how you'd use the model in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1559da99-c4fb-4565-ba74-603405edf9fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load the Champion model by alias\n",
    "champion_model_uri = f\"models:/{model_name}@Champion\"\n",
    "print(f\"üì• Loading model from: {champion_model_uri}\")\n",
    "\n",
    "champion_model = mlflow.pyfunc.load_model(champion_model_uri)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e279102d-ad93-4e57-ac5d-908b77c8127c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Make Batch Predictions\n",
    "\n",
    "Use the loaded model to predict defects on new sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef76130-4711-422d-a920-46e27d82d862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = champion_model.predict(X_test)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"actual_defect\": y_test.values,\n",
    "    \"predicted_defect\": predictions,\n",
    "    \"airflow_rate\": X_test[\"airflow_rate\"].values,\n",
    "    \"rotation_speed\": X_test[\"rotation_speed\"].values,\n",
    "    \"temperature\": X_test[\"temperature\"].values\n",
    "})\n",
    "\n",
    "print(\"üîÆ Predictions:\")\n",
    "display(results_df.head(20))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (results_df[\"actual_defect\"] == results_df[\"predicted_defect\"]).mean()\n",
    "print(f\"\\n‚úÖ Prediction Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18079fbd-c853-4f91-9b43-8c42d5e76c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Mission Accomplished!\n",
    "\n",
    "**What you just did:**\n",
    "1. ‚úÖ **EXPERIMENT** - Trained models with automatic MLflow tracking\n",
    "2. ‚úÖ **REGISTER** - Saved the best model to Unity Catalog with Champion alias\n",
    "3. ‚úÖ **PREDICT (Demo)** - Loaded and tested the model on sample data\n",
    "\n",
    "**You're now ready to:**\n",
    "- Show leadership you have a working predictive model ‚ú®\n",
    "- Deploy this model to production (next notebook covers batch, streaming, and real-time inference)\n",
    "- Track model performance over time\n",
    "- Iterate and improve with new model versions\n",
    "\n",
    "**Next Up:** Move to notebook 6 (ML and AI Inference) to learn production deployment patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ff0f0d-e85a-4860-8fbf-c79da527e9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üöÄ Try This Out: Next Steps\n",
    "\n",
    "Now that you have the MLOps basics down, here are ways to level up:\n",
    "\n",
    "### 1. Train XGBoost with Databricks Assistant\n",
    "\n",
    "Try training an XGBoost model and compare it to the Random Forest:\n",
    "\n",
    "**Steps:**\n",
    "1. Create a new code cell\n",
    "2. Ask Databricks Assistant: \"Train an XGBoost classifier using the same training data with MLflow autologging\"\n",
    "3. Compare the results in the MLflow UI\n",
    "4. Which performs better - Random Forest or XGBoost?\n",
    "\n",
    "**Bonus:** Try LightGBM too!\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Experiment with Different Models\n",
    "\n",
    "Try these other algorithms using the same training code pattern:\n",
    "- **Logistic Regression** - Simple baseline\n",
    "- **LightGBM** - Fast gradient boosting\n",
    "- **XGBoost** - Popular gradient boosting\n",
    "- **Neural Network** - sklearn MLPClassifier\n",
    "\n",
    "**Tip:** Use Databricks Assistant to help with the code!\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Hyperparameter Tuning with Hyperopt\n",
    "\n",
    "Automatically find the best parameters with [Hyperparameter Tuning](https://docs.databricks.com/aws/en/machine-learning/automl-hyperparam-tuning/optuna)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 4. Move to the Next Notebook\n",
    "\n",
    "Ready to deploy your models? The **next notebook (6 ML and AI Inference)** covers:\n",
    "- **Batch predictions** - Score large datasets\n",
    "- **Streaming predictions** - Real-time monitoring\n",
    "- **Model serving APIs** - REST endpoints for applications\n",
    "- **AI Query** - SQL-based inference\n",
    "\n",
    "This is where your trained models go to production! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf164beb-38e7-4d10-a602-25e992b7cf84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- [MLflow Quickstart](https://docs.databricks.com/aws/en/mlflow/quick-start.html)\n",
    "- [MLflow 3 Migration Guide](https://docs.databricks.com/aws/en/mlflow/mlflow-3-install.html)\n",
    "- [Unity Catalog Model Registry](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/index.html)\n",
    "- [Databricks Autologging](https://docs.databricks.com/aws/en/mlflow/databricks-autologging.html)\n",
    "- [Model Deployment Guide](https://docs.databricks.com/aws/en/machine-learning/model-serving/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c7fd88-5942-480a-8bef-52d00cd91f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "5 MLflow and MLops",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
