{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cccac8a-bf4a-48c0-b501-563e44df5c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow for Production AI and ML\n",
    "\n",
    "## The Scenario\n",
    "\n",
    "üõ©Ô∏è **Leadership just gave you the order:** Your team has IoT sensor data streaming in from aircraft engines across 5 factories. By the end of the week, you need to deploy a predictive model to identify potential defects before they cause failures. This notebook gets you from raw data to a production-ready model in 30 minutes.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "‚úÖ **Experiment** - Track model training with MLflow autologging  \n",
    "‚úÖ **Register** - Version control models in Unity Catalog  \n",
    "‚úÖ **Predict** - Load and use models for batch inference  \n",
    "\n",
    "**Key Concepts:**\n",
    "- **MLflow Tracking**: Automatically log parameters, metrics, and models\n",
    "- **Unity Catalog Model Registry**: Enterprise-grade model versioning and governance\n",
    "- **Model Aliases**: Tag models as \"Champion\" or \"Challenger\" for deployment\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- [MLflow Tracking](https://docs.databricks.com/aws/en/mlflow/tracking)\n",
    "- [Databricks Autologging](https://docs.databricks.com/aws/en/mlflow/databricks-autologging)\n",
    "- [Unity Catalog Model Registry](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c483f8e9-6598-487a-9f8d-490586696bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Why MLflow?\n",
    "\n",
    "Without MLflow, data scientists face challenges like:\n",
    "- **Lost experiments** - \"Which hyperparameters gave us that 95% accuracy?\"\n",
    "- **Model chaos** - \"Where's the model we deployed last week?\"\n",
    "- **No reproducibility** - \"I can't recreate these results\"\n",
    "\n",
    "MLflow solves this by providing:\n",
    "- **Experiment Tracking**: Automatic logging of parameters, metrics, and artifacts\n",
    "- **Model Registry**: Centralized model versioning with Unity Catalog\n",
    "- **Deployment**: Seamless path from experiment to production\n",
    "\n",
    "**The MLOps Workflow:**\n",
    "```\n",
    "1. EXPERIMENT ‚Üí Train models, MLflow tracks everything\n",
    "2. REGISTER   ‚Üí Save best model to Unity Catalog\n",
    "3. PREDICT    ‚Üí Use model for batch or real-time inference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "131e1af4-b4f5-45b7-8f44-b746b186425b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup: Connect to IoT Data\n",
    "\n",
    "We'll use the sensor and inspection data from our aircraft engine monitoring system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdc3776c-4e7d-41af-aa4f-bfcec4ed085e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration - update with your catalog/schema\n",
    "catalog = \"josh_melton\"  # Update to your catalog\n",
    "schema = \"default\"       # Update to your schema\n",
    "\n",
    "# Display available tables\n",
    "print(\"Available IoT tables:\")\n",
    "tables = spark.sql(f\"SHOW TABLES IN {catalog}.{schema}\").filter(\"tableName LIKE '%sensor%' OR tableName LIKE '%inspection%'\")\n",
    "display(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "321a4991-5f2b-43dc-a492-0971325b4c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load and Prepare Training Data\n",
    "\n",
    "We'll join sensor readings with inspection results to create a labeled dataset for defect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "850c8844-8c7f-4449-a5aa-568dd7f59e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Load sensor and inspection data\n",
    "sensor_df = spark.table(f\"{catalog}.{schema}.sensor_bronze\")\n",
    "inspection_df = spark.table(f\"{catalog}.{schema}.inspection_bronze\")\n",
    "\n",
    "# Join sensor data with inspection labels\n",
    "# For each device, take the most recent sensor reading before each inspection\n",
    "window_spec = Window.partitionBy(\"device_id\").orderBy(F.col(\"sensor_timestamp\").desc())\n",
    "\n",
    "training_data = (\n",
    "    sensor_df\n",
    "    .withColumnRenamed(\"timestamp\", \"sensor_timestamp\")\n",
    "    .join(\n",
    "        inspection_df.withColumnRenamed(\"timestamp\", \"inspection_timestamp\"),\n",
    "        [\"device_id\"]\n",
    "    )\n",
    "    .filter(F.col(\"sensor_timestamp\") <= F.col(\"inspection_timestamp\"))\n",
    "    .withColumn(\"row_num\", F.row_number().over(window_spec))\n",
    "    .filter(F.col(\"row_num\") == 1)\n",
    "    .select(\n",
    "        \"device_id\",\n",
    "        \"factory_id\", \n",
    "        \"model_id\",\n",
    "        \"airflow_rate\",\n",
    "        \"rotation_speed\",\n",
    "        \"air_pressure\",\n",
    "        \"temperature\",\n",
    "        \"delay\",\n",
    "        \"density\",\n",
    "        F.col(\"defect\").cast(\"int\").alias(\"defect\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {training_data.count():,} records\")\n",
    "print(f\"Defect rate: {training_data.filter('defect = 1').count() / training_data.count() * 100:.2f}%\")\n",
    "\n",
    "display(training_data.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af935d9-ba96-4fca-91fe-239e8d1a727e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Convert to Pandas for Sklearn\n",
    "\n",
    "For this quick example, we'll use scikit-learn. For larger datasets, consider using Spark MLlib or distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a67e94-7e4f-496c-bc01-59099b9e3241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to Pandas\n",
    "pdf = training_data.toPandas()\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [\"airflow_rate\", \"rotation_speed\", \"air_pressure\", \"temperature\", \"delay\", \"density\"]\n",
    "X = pdf[feature_cols]\n",
    "y = pdf[\"defect\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61c15373-deea-44ca-91aa-8411b4b25f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1Ô∏è‚É£ EXPERIMENT: Train Model with MLflow Autologging\n",
    "\n",
    "**Key Point:** Use `mlflow.autolog()` to automatically track everything! No need to manually log parameters, metrics, or models.\n",
    "\n",
    "**What gets auto-logged:**\n",
    "- Model architecture and parameters\n",
    "- Training metrics (accuracy, precision, recall, etc.)\n",
    "- Model artifacts\n",
    "- Feature importances\n",
    "- Training dataset signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e51420ad-acef-44e6-a517-d5f659874f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Enable autologging - this is the magic! ‚ú®\n",
    "mlflow.autolog()\n",
    "\n",
    "# Train model - MLflow automatically tracks everything\n",
    "with mlflow.start_run(run_name=\"IoT Defect Prediction - RF\") as run:\n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate additional metrics (autolog captures most, but we can add custom ones)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c29951c-bc75-4fdc-85e3-1b1dfaac3a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üîç Explore the Databricks MLflow UI\n",
    "\n",
    "**Click the \"Experiment\" button at the top right of this notebook** to open the MLflow UI. You'll see:\n",
    "\n",
    "1. **Runs table** - All your experiments in one place\n",
    "2. **Parameters** - Hyperparameters used (n_estimators, max_depth, etc.)\n",
    "3. **Metrics** - Model performance (accuracy, precision, recall, etc.)\n",
    "4. **Artifacts** - Saved model files, feature importances, and more\n",
    "5. **Charts** - Visualize metric comparisons across runs\n",
    "\n",
    "Try clicking on your run to see all the details that were automatically logged!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54b3bfa0-956e-4d25-92ea-dd0db4a6e0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train Another Model to Compare\n",
    "\n",
    "Let's train a Gradient Boosting model to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ade0bef-a8aa-460b-b207-c6c0f43d07f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Autologging is still enabled from earlier\n",
    "with mlflow.start_run(run_name=\"IoT Defect Prediction - GBM\") as run:\n",
    "    # Train Gradient Boosting\n",
    "    gbm_model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    gbm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = gbm_model.predict(X_test)\n",
    "    y_pred_proba = gbm_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"‚úÖ Run ID: {run.info.run_id}\")\n",
    "    print(f\"üìä Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"üéØ Precision: {precision:.4f}\")\n",
    "    print(f\"üîç Recall: {recall:.4f}\")\n",
    "    print(f\"üìà F1 Score: {f1:.4f}\")\n",
    "    print(f\"üìâ AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4707965c-109e-4507-94b4-fbacae849e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üí° **Pro Tip:** Go back to the MLflow UI and compare the two runs side-by-side. Which model performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa543e08-e7ba-4b85-8ec7-4ca3d4c3230a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2Ô∏è‚É£ REGISTER: Save Model to Unity Catalog\n",
    "\n",
    "The **Unity Catalog Model Registry** is your enterprise model store. It provides:\n",
    "- **Versioning**: Every model update creates a new version\n",
    "- **Lineage**: Track which data and code produced each model\n",
    "- **Governance**: Control who can access and deploy models\n",
    "- **Aliases**: Tag models as \"Champion\", \"Challenger\", \"Staging\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e1c6dc-7d13-4410-9682-8f0d0c71c560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the best model (using the Random Forest run_id from earlier)\n",
    "model_name = f\"{catalog}.{schema}.iot_defect_predictor\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "print(f\"üì¶ Registering model: {model_name}\")\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "print(f\"‚úÖ Registered model version: {model_details.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab7d2954-56de-401c-8801-dd68853b1459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set Model Alias to \"Champion\"\n",
    "\n",
    "Model aliases let you tag specific versions for deployment (e.g., \"Champion\" for production, \"Challenger\" for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e543ab55-9d51-4906-a1c5-d98e7171bcce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Add model description\n",
    "client.update_registered_model(\n",
    "    name=model_name,\n",
    "    description=\"Random Forest model to predict defects in aircraft engine IoT sensors. Trained on sensor readings (airflow, rotation speed, temperature, pressure) and inspection results.\"\n",
    ")\n",
    "\n",
    "# Set the \"Champion\" alias to this version\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"Champion\",\n",
    "    version=model_details.version\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model version {model_details.version} tagged as 'Champion'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88c3543f-3e25-42bb-9335-71ea7d148cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üéØ **View your model in Unity Catalog:**\n",
    "1. Click \"Catalog\" in the left sidebar\n",
    "2. Navigate to your catalog ‚Üí schema ‚Üí \"iot_defect_predictor\"\n",
    "3. See model versions, lineage, and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5ee54fe-51df-49f9-bd6c-bad2c9600338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3Ô∏è‚É£ PREDICT: Load and Use the Model\n",
    "\n",
    "Load the \"Champion\" model and use it for predictions. This is how you'd use the model in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1559da99-c4fb-4565-ba74-603405edf9fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "# Load the Champion model by alias\n",
    "champion_model_uri = f\"models:/{model_name}@Champion\"\n",
    "print(f\"üì• Loading model from: {champion_model_uri}\")\n",
    "\n",
    "champion_model = mlflow.pyfunc.load_model(champion_model_uri)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e279102d-ad93-4e57-ac5d-908b77c8127c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Make Batch Predictions\n",
    "\n",
    "Use the loaded model to predict defects on new sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ef76130-4711-422d-a920-46e27d82d862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = champion_model.predict(X_test)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"actual_defect\": y_test.values,\n",
    "    \"predicted_defect\": predictions,\n",
    "    \"airflow_rate\": X_test[\"airflow_rate\"].values,\n",
    "    \"rotation_speed\": X_test[\"rotation_speed\"].values,\n",
    "    \"temperature\": X_test[\"temperature\"].values\n",
    "})\n",
    "\n",
    "print(\"üîÆ Predictions:\")\n",
    "display(results_df.head(20))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (results_df[\"actual_defect\"] == results_df[\"predicted_defect\"]).mean()\n",
    "print(f\"\\n‚úÖ Prediction Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18079fbd-c853-4f91-9b43-8c42d5e76c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Mission Accomplished!\n",
    "\n",
    "**What you just did:**\n",
    "1. ‚úÖ **EXPERIMENT** - Trained models with automatic MLflow tracking\n",
    "2. ‚úÖ **REGISTER** - Saved the best model to Unity Catalog\n",
    "3. ‚úÖ **PREDICT** - Loaded and used the model for inference\n",
    "\n",
    "**You're now ready to:**\n",
    "- Show leadership you have a working predictive model ‚ú®\n",
    "- Deploy this model to production (see \"Try This Out\" below)\n",
    "- Track model performance over time\n",
    "- Iterate and improve with new versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7ff0f0d-e85a-4860-8fbf-c79da527e9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üöÄ Try This Out: Next Steps\n",
    "\n",
    "Now that you have the MLOps basics down, here are ways to level up:\n",
    "\n",
    "### 1. Real-Time Model Serving\n",
    "Deploy your model as a REST API endpoint:\n",
    "```python\n",
    "# Enable Model Serving (UI: Machine Learning ‚Üí Serving)\n",
    "# Your model will be available at an API endpoint for real-time predictions\n",
    "# Example: https://<workspace>.cloud.databricks.com/serving-endpoints/iot-defect-predictor/invocations\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Real-time defect detection as sensor data streams in\n",
    "- Embed predictions in dashboards or operational tools\n",
    "- Low-latency (<100ms) predictions\n",
    "\n",
    "**Learn more:** [Model Serving Documentation](https://docs.databricks.com/aws/en/machine-learning/model-serving/index.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Streaming Predictions with Structured Streaming\n",
    "Apply your model to streaming sensor data:\n",
    "```python\n",
    "# Load model as UDF\n",
    "predict_udf = mlflow.pyfunc.spark_udf(spark, model_uri=champion_model_uri)\n",
    "\n",
    "# Apply to streaming data\n",
    "stream_df = spark.readStream.table(\"sensor_bronze\")\n",
    "predictions = stream_df.withColumn(\"predicted_defect\", predict_udf(*feature_cols))\n",
    "\n",
    "# Write to output table\n",
    "predictions.writeStream.table(\"sensor_predictions\")\n",
    "```\n",
    "\n",
    "**Use cases:**\n",
    "- Continuous monitoring of all devices\n",
    "- Automated alerting when defects are predicted\n",
    "- Real-time dashboards with predictions\n",
    "\n",
    "**Learn more:** [Structured Streaming + MLflow](https://docs.databricks.com/aws/en/structured-streaming/apply-ml-models.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Monitoring and Drift Detection\n",
    "Track model performance over time:\n",
    "```python\n",
    "# Log inference data\n",
    "mlflow.log_table(predictions, artifact_file=\"predictions.json\")\n",
    "\n",
    "# Monitor for:\n",
    "# - Data drift (are input features changing?)\n",
    "# - Concept drift (is the defect pattern changing?)\n",
    "# - Performance drift (is accuracy decreasing?)\n",
    "```\n",
    "\n",
    "**Learn more:** [Lakehouse Monitoring](https://docs.databricks.com/aws/en/lakehouse-monitoring/index.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. A/B Testing with Multiple Models\n",
    "Compare \"Champion\" vs \"Challenger\" models in production:\n",
    "```python\n",
    "# Tag new model as Challenger\n",
    "client.set_registered_model_alias(model_name, \"Challenger\", new_version)\n",
    "\n",
    "# Route 90% traffic to Champion, 10% to Challenger\n",
    "# Measure which performs better in production\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Hyperparameter Tuning with Hyperopt\n",
    "Automatically find the best parameters:\n",
    "```python\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "import mlflow\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.autolog()\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        return -accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "search_space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
    "    'max_depth': hp.choice('max_depth', [5, 10, 15, 20])\n",
    "}\n",
    "\n",
    "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10)\n",
    "```\n",
    "\n",
    "**Learn more:** [Hyperparameter Tuning](https://docs.databricks.com/aws/en/machine-learning/automl-hyperparam-tuning/index.html)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Feature Store for Reusable Features\n",
    "Create a centralized feature repository:\n",
    "```python\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "# Create feature table\n",
    "fs.create_table(\n",
    "    name=f\"{catalog}.{schema}.sensor_features\",\n",
    "    primary_keys=[\"device_id\"],\n",
    "    df=feature_df\n",
    ")\n",
    "\n",
    "# Models automatically log feature dependencies\n",
    "```\n",
    "\n",
    "**Learn more:** [Feature Store](https://docs.databricks.com/aws/en/machine-learning/feature-store/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf164beb-38e7-4d10-a602-25e992b7cf84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- [MLflow Quickstart](https://docs.databricks.com/aws/en/mlflow/quick-start.html)\n",
    "- [MLflow 3 Migration Guide](https://docs.databricks.com/aws/en/mlflow/mlflow-3-install.html)\n",
    "- [Unity Catalog Model Registry](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/index.html)\n",
    "- [Databricks Autologging](https://docs.databricks.com/aws/en/mlflow/databricks-autologging.html)\n",
    "- [Model Deployment Guide](https://docs.databricks.com/aws/en/machine-learning/model-serving/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5c7fd88-5942-480a-8bef-52d00cd91f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "5 MLflow and MLops",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
