{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6ce40d6c-134a-430f-8225-d403fbeddf4c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "# Agent Bricks: Building an AI Knowledge Assistant\n",
        "\n",
        "**Agent Bricks** is Databricks' streamlined approach for building production-grade AI agents using natural language and pre-configured templates. It automates the complex work of building, optimizing, and deploying AI agents.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "‚úÖ Understand what Agent Bricks Knowledge Assistant does  \n",
        "‚úÖ Create a Knowledge Assistant using the UI  \n",
        "‚úÖ Connect it to PDF documents in a Unity Catalog Volume  \n",
        "‚úÖ Test the assistant with natural language queries  \n",
        "‚úÖ Use AI Functions (`ai_query`, `ai_parse_document`, `ai_extract`) to process documents  \n",
        "\n",
        "---\n",
        "\n",
        "## The Scenario\n",
        "\n",
        "Your team has accumulated aircraft maintenance manuals, technical reports, and research papers as PDFs. Engineers need to quickly find information buried in these documents without manually searching through hundreds of pages.\n",
        "\n",
        "**The solution:** Build a Knowledge Assistant that can answer questions about the content in these PDFs using natural language.\n",
        "\n",
        "---\n",
        "\n",
        "## What is Agent Bricks Knowledge Assistant?\n",
        "\n",
        "**Agent Bricks Knowledge Assistant** is a pre-built template that:\n",
        "- Automatically indexes documents from Unity Catalog Volumes\n",
        "- Uses retrieval-augmented generation (RAG) to answer questions\n",
        "- Provides source citations for transparency\n",
        "- Requires no code to get started\n",
        "\n",
        "**Why use it:**\n",
        "- ‚ö° **Fast setup** - Minutes, not weeks\n",
        "- üéØ **Accurate answers** - Cites sources from your documents\n",
        "- üîÑ **Continuous optimization** - Databricks improves the system over time\n",
        "- üöÄ **Production-ready** - Deploy as an API endpoint immediately\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. Configuration\n",
        "2. Understanding Agent Bricks Knowledge Assistant\n",
        "3. Creating Your Knowledge Assistant (UI)\n",
        "4. Testing the Knowledge Assistant\n",
        "5. AI Functions: `ai_query`\n",
        "6. AI Functions: `ai_parse_document` and `ai_extract`\n",
        "7. Summary\n",
        "\n",
        "---\n",
        "\n",
        "**References:**\n",
        "- [Agent Bricks Overview](https://docs.databricks.com/aws/en/generative-ai/agent-bricks)\n",
        "- [Knowledge Assistant](https://docs.databricks.com/aws/en/generative-ai/agent-bricks/knowledge-assistant)\n",
        "- [AI Functions](https://docs.databricks.com/aws/en/large-language-models/ai-functions-example)\n",
        "- [`ai_parse_document` Function](https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_parse_document)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e74e5c44-6a7d-4e79-abb2-b3a0d8e99d7c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "# Configuration\n",
        "import re\n",
        "\n",
        "CATALOG = 'dwx_express_insights_platform_dev_working'\n",
        "READ_SCHEMA = 'db_crash_course'  # Shared schema (read-only)\n",
        "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        "username_base = username.split('@')[0]  # Extract username before @ symbol\n",
        "WRITE_SCHEMA = re.sub(r'[^a-zA-Z0-9_]', '_', username_base)  # Replace special chars with _\n",
        "\n",
        "# Create personal schema for any writes\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{WRITE_SCHEMA}\")\n",
        "\n",
        "# PDF documents volume path (created during setup)\n",
        "PDF_VOLUME_PATH = f\"/Volumes/{CATALOG}/{READ_SCHEMA}/pdf_documents\"\n",
        "\n",
        "print(f\"‚úÖ Using catalog: {CATALOG}\")\n",
        "print(f\"üìñ Reading from schema: {READ_SCHEMA} (shared)\")\n",
        "print(f\"‚úçÔ∏è  Writing to schema: {WRITE_SCHEMA} (your personal schema)\")\n",
        "print(f\"üìÑ PDF documents at: {PDF_VOLUME_PATH}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bc75cf37-9b76-4519-92a1-710ce3afc834",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 1. Understanding Agent Bricks Knowledge Assistant\n",
        "\n",
        "### What is Agent Bricks?\n",
        "\n",
        "**Agent Bricks** is a low-code/no-code way to build AI agents on Databricks. Instead of writing complex RAG (Retrieval-Augmented Generation) pipelines yourself, Agent Bricks provides pre-built templates that automatically:\n",
        "\n",
        "1. **Index your documents** - Automatically chunks and vectorizes content\n",
        "2. **Select optimal models** - Tries different embedding and LLM models\n",
        "3. **Optimize retrieval** - Fine-tunes retrieval parameters for accuracy\n",
        "4. **Deploy as API** - Creates production-ready endpoints\n",
        "5. **Continuous improvement** - Monitors performance and suggests improvements\n",
        "\n",
        "### What is a Knowledge Assistant?\n",
        "\n",
        "A **Knowledge Assistant** is a specific Agent Bricks template designed to:\n",
        "- Answer questions based on your documents (PDFs, text files, etc.)\n",
        "- Provide source citations for every answer\n",
        "- Handle follow-up questions with conversation context\n",
        "- Scale to thousands of documents\n",
        "\n",
        "**Under the hood, it uses:**\n",
        "- Vector search for semantic document retrieval\n",
        "- LLMs (Large Language Models) for answer generation\n",
        "- RAG (Retrieval-Augmented Generation) architecture\n",
        "- Databricks-optimized infrastructure\n",
        "\n",
        "### Benefits of Agent Bricks Knowledge Assistant\n",
        "\n",
        "‚úÖ **No code required** - Build through the UI in minutes  \n",
        "‚úÖ **Automatic optimization** - Databricks tunes retrieval and generation  \n",
        "‚úÖ **Source citations** - Every answer references specific documents  \n",
        "‚úÖ **Production-ready** - Deploy immediately as a REST API  \n",
        "‚úÖ **Continuous learning** - System improves over time  \n",
        "\n",
        "### When to Use Knowledge Assistant\n",
        "\n",
        "- **Technical documentation search** - Manuals, specs, procedures\n",
        "- **Research paper analysis** - Scientific literature review\n",
        "- **Policy and compliance** - Legal documents, regulations\n",
        "- **Customer support** - Knowledge base Q&A\n",
        "- **Internal wiki search** - Company documentation\n",
        "\n",
        "### Requirements\n",
        "\n",
        "- Unity Catalog enabled workspace\n",
        "- Documents stored in a Unity Catalog Volume\n",
        "- Supported formats: PDF, TXT, DOCX, HTML, Markdown\n",
        "- Serverless compute (for optimal performance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "95fdd0c0-1300-4d8a-828c-a5075850bdf1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 2. Creating Your Knowledge Assistant (UI)\n",
        "\n",
        "Now let's create a Knowledge Assistant that can answer questions about the aircraft documentation PDFs.\n",
        "\n",
        "### Step-by-Step Instructions\n",
        "\n",
        "Follow these steps in the Databricks UI to create your Knowledge Assistant:\n",
        "\n",
        "**Step 1: Navigate to Agent Bricks**\n",
        "\n",
        "1. In the Databricks workspace, click **AI** in the left sidebar\n",
        "2. Select **Agent Bricks** (or **AI Builder**)\n",
        "3. Click **Create Agent** or **+ New Agent**\n",
        "\n",
        "**Step 2: Select Knowledge Assistant Template**\n",
        "\n",
        "1. Choose the **Knowledge Assistant** template\n",
        "2. Give your assistant a name (e.g., \"Aircraft Documentation Assistant\")\n",
        "3. Optionally add a description: \"Answers questions about aircraft maintenance and technical documentation\"\n",
        "\n",
        "**Step 3: Configure Data Source**\n",
        "\n",
        "1. Under **Data Source**, select **Unity Catalog Volume**\n",
        "2. Browse to or enter the volume path:\n",
        "   ```\n",
        "   /Volumes/dwx_express_insights_platform_dev_working/db_crash_course/pdf_documents\n",
        "   ```\n",
        "3. The system will automatically detect the PDF files in the volume\n",
        "\n",
        "**Step 4: Configure Settings (Optional)**\n",
        "\n",
        "Keep the defaults, but you can optionally adjust:\n",
        "- **Chunk size**: How documents are split (default: 1000 tokens)\n",
        "- **Overlap**: Overlap between chunks (default: 200 tokens)\n",
        "- **Top K**: Number of relevant chunks to retrieve (default: 5)\n",
        "- **Model**: LLM used for answer generation (default: optimized by Databricks)\n",
        "\n",
        "**Step 5: Create and Deploy**\n",
        "\n",
        "1. Click **Create** to build the agent\n",
        "2. Agent Bricks will:\n",
        "   - Index and chunk all PDF documents\n",
        "   - Create vector embeddings\n",
        "   - Set up the RAG pipeline\n",
        "   - Deploy a serverless endpoint\n",
        "3. Wait 2-5 minutes for indexing to complete (check status indicator)\n",
        "\n",
        "**What happens behind the scenes:**\n",
        "- Documents are parsed and chunked into manageable pieces\n",
        "- Each chunk is converted to a vector embedding for semantic search\n",
        "- A vector index is created in Unity Catalog\n",
        "- A serving endpoint is deployed for real-time queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ef89cfb2-67c0-49be-afc6-db72ce447ed4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 3. Testing Your Knowledge Assistant\n",
        "\n",
        "Once your Knowledge Assistant is deployed, it's time to test it with real queries!\n",
        "\n",
        "### Testing in the UI\n",
        "\n",
        "**Step 1: Open the Chat Interface**\n",
        "\n",
        "1. After deployment completes, you'll see a **Chat** interface in the Agent Bricks UI\n",
        "2. Or click on your agent name to open the chat window\n",
        "\n",
        "**Step 2: Ask Questions About Your PDFs**\n",
        "\n",
        "Try these example questions (adjust based on the actual PDF content):\n",
        "\n",
        "**Question 1: General Information**\n",
        "```\n",
        "What maintenance procedures are described in the aircraft documentation?\n",
        "```\n",
        "\n",
        "**Question 2: Specific Details**\n",
        "```\n",
        "What are the key failure modes mentioned in the run-to-failure simulation dataset?\n",
        "```\n",
        "\n",
        "**Question 3: Technical Specifications**\n",
        "```\n",
        "What ATM (Air Traffic Management) concepts are defined in the NASA ontology?\n",
        "```\n",
        "\n",
        "**Question 4: Complex Query**\n",
        "```\n",
        "What are the main differences between the maintenance approaches described across the documents?\n",
        "```\n",
        "\n",
        "### Understanding the Results\n",
        "\n",
        "For each answer, the Knowledge Assistant provides:\n",
        "\n",
        "‚úÖ **Answer text** - Generated response based on retrieved documents  \n",
        "‚úÖ **Source citations** - Which PDFs and pages were used  \n",
        "‚úÖ **Confidence score** - How confident the system is in the answer  \n",
        "‚úÖ **Retrieved chunks** - The actual text excerpts used  \n",
        "\n",
        "### What Makes a Good Answer?\n",
        "\n",
        "- **Accurate**: Information matches the source documents\n",
        "- **Cited**: References specific documents/pages\n",
        "- **Concise**: Answers the question directly\n",
        "- **Contextual**: Uses relevant information from multiple chunks if needed\n",
        "\n",
        "### Quick Evaluation\n",
        "\n",
        "Notice:\n",
        "- Does the answer make sense?\n",
        "- Are the sources relevant?\n",
        "- Does it handle questions outside the document scope appropriately?\n",
        "\n",
        "**Note:** For this training, we're keeping it simple. In production, you'd run more extensive evaluations using test question sets, but that's beyond our scope today.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6614953-6ff1-4f5d-b01b-1a9ed2b40e7d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 4. AI Functions Overview\n",
        "\n",
        "Beyond Agent Bricks, Databricks provides **AI Functions** - SQL functions that let you call generative AI models directly in your queries. These functions are powerful tools for document processing and information extraction.\n",
        "\n",
        "### Three Key AI Functions\n",
        "\n",
        "**1. `ai_query()`** - Call LLMs directly\n",
        "- Ask questions or generate text\n",
        "- Simplest way to use LLMs in SQL\n",
        "- Great for one-off queries\n",
        "\n",
        "**2. `ai_parse_document()`** - Extract structured content from documents\n",
        "- Parses PDFs, images, Office docs\n",
        "- Extracts text, tables, figures\n",
        "- Returns structured JSON with layout information\n",
        "\n",
        "**3. `ai_extract()`** - Extract entities from text\n",
        "- Pull out names, dates, organizations, etc.\n",
        "- Schema-on-read for unstructured text\n",
        "- Returns structured data as columns\n",
        "\n",
        "### Why Use AI Functions?\n",
        "\n",
        "‚úÖ **Scalable** - Process thousands of documents in parallel  \n",
        "‚úÖ **Integrated** - Works directly in SQL and PySpark  \n",
        "‚úÖ **Cost-effective** - Only pay for what you use  \n",
        "‚úÖ **No infrastructure** - Serverless execution  \n",
        "\n",
        "Let's see these in action!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dc23cd65-92cc-4741-ab26-0e598266ae81",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 5. AI Functions Example 1: Simple `ai_query`\n",
        "\n",
        "The simplest AI Function is `ai_query()` - it lets you call an LLM directly from SQL or Python.\n",
        "\n",
        "### Basic Example\n",
        "\n",
        "Let's ask a simple question to verify the function works:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "170b79d1-4745-4309-85d4-6aa8643201c3",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "%sql\n",
        "SELECT ai_query(\n",
        "  'databricks-meta-llama-3-1-70b-instruct',\n",
        "  'What is the capital of France? Answer in one sentence.'\n",
        ") AS answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6073f0b8-e25b-437e-ab6c-59ce389ccfcc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "## 6. AI Functions Example 2: Parse and Extract from PDFs\n",
        "\n",
        "Now let's do something more powerful - parse PDF documents and extract structured information!\n",
        "\n",
        "### What We'll Do\n",
        "\n",
        "1. Read PDFs from the Unity Catalog Volume as binary files\n",
        "2. Use `ai_parse_document()` to extract text and structure\n",
        "3. Use `ai_extract()` to pull out specific entities (organizations, dates, etc.)\n",
        "4. Save the results to a table for further analysis\n",
        "\n",
        "### Step 1: Read and Parse PDFs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "378fc1fc-f8c5-402c-acee-c05cc7ee91f8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "from pyspark.sql.functions import expr, col\n",
        "\n",
        "# Read PDFs from the volume as binary files\n",
        "pdf_df = spark.read.format(\"binaryFile\").load(PDF_VOLUME_PATH)\n",
        "\n",
        "print(f\"Found {pdf_df.count()} PDF files\")\n",
        "print(\"\\nPDF files:\")\n",
        "pdf_df.select(\"path\").show(truncate=False)\n",
        "\n",
        "# Parse one document as an example (using the first PDF)\n",
        "# ai_parse_document extracts text, tables, and structure\n",
        "parsed_df = (\n",
        "    pdf_df\n",
        "    .limit(1)  # Just process one PDF for this example\n",
        "    .withColumn(\"parsed\", expr(\"ai_parse_document(content)\"))\n",
        "    .select(\n",
        "        \"path\",\n",
        "        \"parsed\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Document parsed successfully!\")\n",
        "print(\"The parsed output contains structured information about the document.\")\n",
        "\n",
        "# Display the parsed structure\n",
        "parsed_df.display()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Extract Structured Information\n",
        "\n",
        "Now let's extract specific entities from the parsed text using `ai_extract()`:\n",
        "\n",
        "**What `ai_extract()` does:**\n",
        "- Takes text and a list of entity types to extract\n",
        "- Returns structured data (names, dates, organizations, etc.)\n",
        "- Works great for turning unstructured documents into structured tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract text content from parsed elements\n",
        "from pyspark.sql.functions import explode, concat_ws, transform\n",
        "\n",
        "# Get the text from all elements in the document\n",
        "text_extracted_df = (\n",
        "    parsed_df\n",
        "    .withColumn(\n",
        "        \"text_content\",\n",
        "        concat_ws(\n",
        "            \" \",\n",
        "            transform(\n",
        "                expr(\"parsed.document.elements\"),\n",
        "                lambda x: x.content\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    .select(\"path\", \"text_content\")\n",
        ")\n",
        "\n",
        "# Use ai_extract to pull out specific entities\n",
        "# We'll look for: organizations, dates, locations, and technical terms\n",
        "extracted_df = (\n",
        "    text_extracted_df\n",
        "    .withColumn(\n",
        "        \"extracted_entities\",\n",
        "        expr(\"\"\"\n",
        "            ai_extract(\n",
        "                substring(text_content, 1, 5000),\n",
        "                array('organization', 'date', 'location', 'technical_term')\n",
        "            )\n",
        "        \"\"\")\n",
        "    )\n",
        "    .select(\n",
        "        \"path\",\n",
        "        col(\"extracted_entities.organization\").alias(\"organizations\"),\n",
        "        col(\"extracted_entities.date\").alias(\"dates\"),\n",
        "        col(\"extracted_entities.location\").alias(\"locations\"),\n",
        "        col(\"extracted_entities.technical_term\").alias(\"technical_terms\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Write results to a table in your personal schema\n",
        "output_table = f\"{CATALOG}.{WRITE_SCHEMA}.parsed_pdf_entities\"\n",
        "extracted_df.write.mode(\"overwrite\").saveAsTable(output_table)\n",
        "\n",
        "print(f\"‚úÖ Extracted entities saved to: {output_table}\")\n",
        "print(f\"   Table contains structured information extracted from PDF\")\n",
        "\n",
        "# Display the results\n",
        "spark.table(output_table).display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What We Just Did\n",
        "\n",
        "In just a few lines of code, we:\n",
        "\n",
        "1. ‚úÖ **Read PDF documents** from Unity Catalog Volume\n",
        "2. ‚úÖ **Parsed document structure** using `ai_parse_document()`\n",
        "3. ‚úÖ **Extracted entities** (organizations, dates, locations) using `ai_extract()`\n",
        "4. ‚úÖ **Saved structured data** to a Delta table for analysis\n",
        "\n",
        "**Real-world applications:**\n",
        "- **Invoice processing**: Extract vendor names, amounts, dates\n",
        "- **Contract analysis**: Pull out parties, terms, dates\n",
        "- **Research paper mining**: Extract authors, institutions, findings\n",
        "- **Resume parsing**: Get names, companies, dates, skills\n",
        "\n",
        "**Scaling this up:**\n",
        "- Remove the `.limit(1)` to process all PDFs\n",
        "- Use Databricks Jobs to run on a schedule\n",
        "- Process thousands of documents in parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Congratulations! You've learned how to build AI agents and use AI Functions on Databricks.\n",
        "\n",
        "### What You Accomplished\n",
        "\n",
        "‚úÖ **Understood Agent Bricks** - Low-code AI agent building platform  \n",
        "‚úÖ **Created a Knowledge Assistant** - Built through UI in minutes  \n",
        "‚úÖ **Indexed PDF documents** - Connected assistant to Unity Catalog Volume  \n",
        "‚úÖ **Tested with queries** - Asked natural language questions about documents  \n",
        "‚úÖ **Used `ai_query()`** - Called LLMs directly from SQL  \n",
        "‚úÖ **Used `ai_parse_document()`** - Extracted structure from PDFs  \n",
        "‚úÖ **Used `ai_extract()`** - Pulled entities into structured tables  \n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "**Agent Bricks Knowledge Assistant:**\n",
        "1. **No-code RAG** - Build document Q&A systems through the UI\n",
        "2. **Automatic optimization** - Databricks tunes retrieval and generation\n",
        "3. **Source citations** - Every answer references specific documents\n",
        "4. **Production-ready** - Deploy immediately as REST API\n",
        "5. **Use case**: Technical documentation, research papers, policies\n",
        "\n",
        "**AI Functions:**\n",
        "1. **`ai_query()`** - Direct LLM access from SQL/Python\n",
        "2. **`ai_parse_document()`** - Extract text, tables, layout from documents\n",
        "3. **`ai_extract()`** - Pull structured entities from unstructured text\n",
        "4. **Scalable** - Process thousands of documents in parallel\n",
        "5. **Integrated** - Works seamlessly with Delta tables and Unity Catalog\n",
        "\n",
        "### Architecture Pattern\n",
        "\n",
        "```\n",
        "PDFs in Volume ‚Üí ai_parse_document() ‚Üí Structured Text\n",
        "                          ‚Üì\n",
        "                   ai_extract() ‚Üí Entities\n",
        "                          ‚Üì\n",
        "                    Delta Table ‚Üí Analytics/ML\n",
        "```\n",
        "\n",
        "### Real-World Applications\n",
        "\n",
        "**Knowledge Assistant:**\n",
        "- Technical support documentation search\n",
        "- Legal and compliance document Q&A\n",
        "- Research paper analysis\n",
        "- Internal wiki search\n",
        "- Policy and procedure lookup\n",
        "\n",
        "**AI Functions:**\n",
        "- Invoice and receipt processing (extract amounts, vendors, dates)\n",
        "- Contract analysis (extract parties, terms, obligations)\n",
        "- Resume parsing (extract names, companies, skills)\n",
        "- Scientific literature review (extract findings, authors)\n",
        "- Medical records processing (extract diagnoses, medications)\n",
        "\n",
        "---\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "**Next Notebook (5 MLflow and MLOps)**: Learn to train custom models, track experiments, and manage the ML lifecycle with MLflow.\n",
        "\n",
        "**Next Notebook (6 ML and AI Inference)**: Deploy models for batch, streaming, and real-time predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## Try This Out (Optional Extensions)\n",
        "\n",
        "Want more practice? Try these exercises:\n",
        "\n",
        "### 1. Process All PDFs\n",
        "\n",
        "Remove the `.limit(1)` and process all PDFs in the volume:\n",
        "\n",
        "```python\n",
        "# Process ALL PDFs instead of just one\n",
        "parsed_df = (\n",
        "    pdf_df  # Remove .limit(1)\n",
        "    .withColumn(\"parsed\", expr(\"ai_parse_document(content)\"))\n",
        ")\n",
        "```\n",
        "\n",
        "### 2. Extract Different Entities\n",
        "\n",
        "Try extracting different types of information:\n",
        "\n",
        "```python\n",
        "# Extract technical specifications\n",
        "expr(\"\"\"\n",
        "    ai_extract(\n",
        "        text_content,\n",
        "        array('model_number', 'specification', 'measurement', 'requirement')\n",
        "    )\n",
        "\"\"\")\n",
        "```\n",
        "\n",
        "### 3. Build a Custom Query\n",
        "\n",
        "Use `ai_query()` to summarize the extracted information:\n",
        "\n",
        "```sql\n",
        "SELECT ai_query(\n",
        "  'databricks-meta-llama-3-1-70b-instruct',\n",
        "  CONCAT('Summarize these key points: ', organizations)\n",
        ") AS summary\n",
        "FROM parsed_pdf_entities\n",
        "```\n",
        "\n",
        "### 4. Chain AI Functions Together\n",
        "\n",
        "Combine multiple AI functions for complex processing:\n",
        "\n",
        "```python\n",
        "# Parse ‚Üí Extract ‚Üí Query pattern\n",
        "result_df = (\n",
        "    pdf_df\n",
        "    .withColumn(\"parsed\", expr(\"ai_parse_document(content)\"))\n",
        "    .withColumn(\"text\", expr(\"parsed.document.elements[0].content\"))\n",
        "    .withColumn(\n",
        "        \"summary\",\n",
        "        expr(\"\"\"ai_query(\n",
        "            'databricks-meta-llama-3-1-70b-instruct',\n",
        "            CONCAT('Summarize in 2 sentences: ', text)\n",
        "        )\"\"\")\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "### 5. Add More Documents\n",
        "\n",
        "Upload your own PDFs to the volume and query them:\n",
        "\n",
        "```python\n",
        "# Upload a new PDF to the volume\n",
        "dbutils.fs.cp(\n",
        "    \"file:/path/to/your/document.pdf\",\n",
        "    f\"{PDF_VOLUME_PATH}/your_document.pdf\"\n",
        ")\n",
        "\n",
        "# Re-index in your Knowledge Assistant to include the new document\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Additional Resources:**\n",
        "- [Agent Bricks Documentation](https://docs.databricks.com/aws/en/generative-ai/agent-bricks)\n",
        "- [Knowledge Assistant Guide](https://docs.databricks.com/aws/en/generative-ai/agent-bricks/knowledge-assistant)\n",
        "- [AI Functions Overview](https://docs.databricks.com/aws/en/large-language-models/ai-functions)\n",
        "- [`ai_parse_document` Reference](https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_parse_document)\n",
        "- [Mosaic AI Agent Framework](https://docs.databricks.com/aws/en/generative-ai/agent-framework/)\n",
        "\n",
        "**Great job!** You now have the skills to build AI agents and process documents with AI Functions. üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0a2924ff-0cbd-4f30-adbc-d6918d3d9eb1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "4"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "4 AutoML",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}