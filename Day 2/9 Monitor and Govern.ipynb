{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Monitor and Govern Databricks Workspaces\n\nUse system tables to monitor usage, costs, and implement governance with Unity Catalog.\n\n## What You'll Learn\n\n\u2705 Query system tables for observability  \n\u2705 Analyze billing and cost allocation  \n\u2705 Monitor workspace usage and performance  \n\u2705 Implement Unity Catalog security  \n\u2705 Create governance dashboards  \n\n**Note**: Since students won't have access to actual system tables, we'll use synthetic data that matches the schema.\n\n---\n\n**References:**\n- [System Tables](https://docs.databricks.com/aws/en/admin/system-tables/)\n- [Billing Tables](https://docs.databricks.com/aws/en/admin/system-tables/billing)\n- [Unity Catalog Governance](https://docs.databricks.com/aws/en/data-governance/unity-catalog/)\n- [Observability Dashboards](https://github.com/CodyAustinDavis/dbsql_sme/tree/main/Observability%20Dashboards%20and%20DBA%20Resources)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. System Tables Overview\n\n### What are System Tables?\n\n**System Tables** provide observability into:\n- Billing and usage\n- Query execution\n- Warehouse performance\n- Audit logs\n- Lineage information\n\n### Available Schemas\n\n```\nsystem.billing.*        - Cost and usage data\nsystem.compute.*        - Cluster and warehouse metrics\nsystem.query.*          - Query execution logs\nsystem.audit.*          - Audit logs\nsystem.lineage.*        - Data lineage\n```\n\n### Access Requirements\n\n**In Production:**\n- Account admin privileges\n- Unity Catalog enabled\n- System tables schema access\n\n**In This Training:**\n- We'll use synthetic data with matching schemas\n- Demonstrates real-world queries and patterns\n\n---\n\n## 2. Billing and Cost Analysis\n\n### Synthetic Billing Data Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create synthetic billing data for training\nfrom pyspark.sql import functions as F\nfrom datetime import datetime, timedelta\nimport random\n\n# Generate sample billing records\ndates = [(datetime.now() - timedelta(days=x)).strftime('%Y-%m-%d') for x in range(30)]\nworkspaces = ['prod-workspace', 'dev-workspace', 'staging-workspace']\nsku_names = ['JOBS_COMPUTE', 'ALL_PURPOSE_COMPUTE', 'SQL_COMPUTE', 'DELTA_LIVE_TABLES']\nusers = ['user1@company.com', 'user2@company.com', 'user3@company.com', 'system']\n\nbilling_data = []\nfor date in dates:\n    for _ in range(50):\n        billing_data.append({\n            'usage_date': date,\n            'workspace_id': random.choice(workspaces),\n            'sku_name': random.choice(sku_names),\n            'usage_quantity': round(random.uniform(0.1, 10.0), 2),\n            'usage_unit': 'DBU',\n            'list_price': round(random.uniform(0.1, 2.0), 2),\n            'usage_metadata': {\n                'job_id': f'job_{random.randint(1, 100)}',\n                'cluster_id': f'cluster_{random.randint(1, 20)}',\n                'user': random.choice(users)\n            }\n        })\n\nbilling_df = spark.createDataFrame(billing_data)\nbilling_df.write.mode('overwrite').saveAsTable('training.system_billing')\n\nprint('\u2705 Synthetic billing data created')\nbilling_df.limit(10).display()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Cost Analysis Queries\n\n**Total Cost by Day:**\n```sql\nSELECT \n  usage_date,\n  SUM(usage_quantity * list_price) as total_cost\nFROM training.system_billing\nGROUP BY usage_date\nORDER BY usage_date DESC;\n```\n\n**Cost by Workspace:**\n```sql\nSELECT \n  workspace_id,\n  SUM(usage_quantity * list_price) as total_cost,\n  COUNT(*) as num_operations\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 30\nGROUP BY workspace_id\nORDER BY total_cost DESC;\n```\n\n**Cost by SKU Type:**\n```sql\nSELECT \n  sku_name,\n  SUM(usage_quantity) as total_dbus,\n  SUM(usage_quantity * list_price) as total_cost,\n  AVG(usage_quantity * list_price) as avg_cost_per_operation\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 30\nGROUP BY sku_name\nORDER BY total_cost DESC;\n```\n\n**Cost by User:**\n```sql\nSELECT \n  usage_metadata.user,\n  COUNT(*) as operations,\n  SUM(usage_quantity * list_price) as total_cost\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 30\nGROUP BY usage_metadata.user\nORDER BY total_cost DESC\nLIMIT 10;\n```\n\n---\n\n## 3. Usage Monitoring\n\n### Warehouse Usage\n\n**Query Execution Metrics:**\n```sql\n-- Most expensive queries\nSELECT \n  query_id,\n  query_text,\n  execution_time_ms,\n  rows_produced,\n  bytes_scanned,\n  compute_cost\nFROM training.query_history\nWHERE query_start_time >= CURRENT_DATE - 7\nORDER BY compute_cost DESC\nLIMIT 20;\n```\n\n**Query Patterns:**\n```sql\n-- Most common query patterns\nSELECT \n  REGEXP_EXTRACT(query_text, 'FROM\\s+(\\w+)', 1) as table_name,\n  COUNT(*) as query_count,\n  AVG(execution_time_ms) as avg_duration_ms\nFROM training.query_history\nGROUP BY table_name\nHAVING table_name IS NOT NULL\nORDER BY query_count DESC;\n```\n\n---\n\n## 4. Unity Catalog Security\n\n### Access Control\n\n**Grant Privileges:**\n```sql\n-- Grant SELECT on schema\nGRANT SELECT ON SCHEMA default.db_crash_course TO `data-analysts`;\n\n-- Grant table access\nGRANT SELECT ON TABLE default.db_crash_course.sensor_enriched TO `data-analysts`;\n\n-- Grant usage on catalog\nGRANT USAGE ON CATALOG default TO `data-analysts`;\n```\n\n**Row-Level Security:**\n```sql\n-- Create row filter\nCREATE FUNCTION default.db_crash_course.filter_by_region(region STRING)\nRETURN region IN (\n  SELECT region FROM user_permissions \n  WHERE user_email = current_user()\n);\n\n-- Apply filter\nALTER TABLE default.db_crash_course.sensor_enriched\nSET ROW FILTER default.db_crash_course.filter_by_region(region) ON (region);\n```\n\n**Column Masking:**\n```sql\n-- Mask sensitive columns\nCREATE FUNCTION default.db_crash_course.mask_device_id(device_id STRING)\nRETURN CASE \n  WHEN is_member('admin') THEN device_id\n  ELSE CONCAT('***', SUBSTRING(device_id, -4, 4))\nEND;\n\n-- Apply mask\nALTER TABLE default.db_crash_course.sensor_enriched\nALTER COLUMN device_id\nSET MASK default.db_crash_course.mask_device_id;\n```\n\n### Audit Logging\n\n**Track Data Access:**\n```sql\nSELECT \n  event_time,\n  user_identity.email as user,\n  request_params.table_full_name as table_accessed,\n  action_name\nFROM system.access.audit\nWHERE action_name IN ('SELECT', 'UPDATE', 'DELETE')\n  AND event_date >= CURRENT_DATE - 7\nORDER BY event_time DESC;\n```\n\n---\n\n## 5. Observability Dashboards\n\n### Create Cost Dashboard\n\n**Key Visualizations:**\n\n1. **Daily Cost Trend** (Line Chart)\n```sql\nSELECT usage_date, SUM(usage_quantity * list_price) as cost\nFROM training.system_billing\nGROUP BY usage_date\nORDER BY usage_date;\n```\n\n2. **Cost by Workspace** (Bar Chart)\n```sql\nSELECT workspace_id, SUM(usage_quantity * list_price) as cost\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 30\nGROUP BY workspace_id;\n```\n\n3. **Top Cost Drivers** (Table)\n```sql\nSELECT \n  usage_metadata.job_id,\n  sku_name,\n  SUM(usage_quantity * list_price) as total_cost\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 7\nGROUP BY usage_metadata.job_id, sku_name\nORDER BY total_cost DESC\nLIMIT 20;\n```\n\n4. **User Cost Allocation** (Pie Chart)\n```sql\nSELECT \n  usage_metadata.user,\n  SUM(usage_quantity * list_price) as cost\nFROM training.system_billing\nWHERE usage_date >= CURRENT_DATE - 30\nGROUP BY usage_metadata.user;\n```\n\n---\n\n## Summary\n\n\u2705 **System tables** - Observability into usage and costs  \n\u2705 **Billing analysis** - Track and allocate costs  \n\u2705 **Usage monitoring** - Query patterns and performance  \n\u2705 **Unity Catalog security** - Row filters and column masking  \n\u2705 **Governance dashboards** - Visual cost tracking  \n\n### Key Takeaways:\n\n1. **Monitor costs regularly** - Daily/weekly review\n2. **Implement cost allocation** - Tag and track by team/project\n3. **Use row-level security** - Protect sensitive data\n4. **Audit access** - Track who accesses what\n5. **Create dashboards** - Visualize key metrics\n\n### Cost Optimization Tips:\n\n- Use job clusters instead of all-purpose\n- Enable auto-termination\n- Right-size clusters\n- Use spot instances where possible\n- Schedule non-urgent jobs for off-peak hours\n- Archive old data to cheaper storage\n\n---\n\n**Additional Resources:**\n- [System Tables Guide](https://docs.databricks.com/aws/en/admin/system-tables/)\n- [Unity Catalog Security](https://docs.databricks.com/aws/en/data-governance/unity-catalog/access-control)\n- [Observability Examples](https://github.com/CodyAustinDavis/dbsql_sme/tree/main/Observability%20Dashboards%20and%20DBA%20Resources)\n- [Cost Management](https://docs.databricks.com/aws/en/admin/account-settings/usage-detail-tags)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}