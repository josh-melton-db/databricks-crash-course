{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: Automated Machine Learning for Defect Prediction\n",
    "\n",
    "**Databricks AutoML** automatically builds machine learning models with minimal code. It tries multiple algorithms, tunes hyperparameters, and provides a leaderboard of the best models.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "✅ Set up data for AutoML  \n",
    "✅ Run classification experiments to predict defects  \n",
    "✅ Review model performance and metrics  \n",
    "✅ Deploy the best model for predictions  \n",
    "✅ Understand feature importance  \n",
    "\n",
    "---\n",
    "\n",
    "## Use Case: Predicting Device Defects\n",
    "\n",
    "We'll use AutoML to predict whether a device will have defects based on sensor readings. This can help:\n",
    "- **Preventive maintenance**: Identify devices at risk before failure\n",
    "- **Quality control**: Catch issues early in production\n",
    "- **Cost reduction**: Minimize downtime and repairs\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Understanding AutoML](#understanding)\n",
    "2. [Preparing Data](#data-prep)\n",
    "3. [Running Classification Experiment](#classification)\n",
    "4. [Reviewing Results](#results)\n",
    "5. [Using the Model](#using-model)\n",
    "6. [Advanced: Regression Example](#regression)\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- [AutoML Overview](https://docs.databricks.com/aws/en/machine-learning/automl/)\n",
    "- [Classification](https://docs.databricks.com/aws/en/machine-learning/automl/classification)\n",
    "- [Regression](https://docs.databricks.com/aws/en/machine-learning/automl/regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CATALOG = 'default'\n",
    "SCHEMA = 'db_crash_course'\n",
    "\n",
    "print(f\"Using: {CATALOG}.{SCHEMA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding AutoML <a id=\"understanding\"></a>\n",
    "\n",
    "### What is Databricks AutoML?\n",
    "\n",
    "AutoML automates the machine learning workflow:\n",
    "1. **Data preprocessing** - Handles missing values, encoding, scaling\n",
    "2. **Feature engineering** - Creates derived features automatically\n",
    "3. **Model selection** - Tries multiple algorithms (Random Forest, XGBoost, LightGBM, etc.)\n",
    "4. **Hyperparameter tuning** - Optimizes model parameters\n",
    "5. **Model evaluation** - Compares models using relevant metrics\n",
    "\n",
    "### Supported Problem Types:\n",
    "\n",
    "- **Classification**: Predict categories (e.g., defect/no defect)\n",
    "- **Regression**: Predict continuous values (e.g., temperature)\n",
    "- **Forecasting**: Predict time series values (e.g., future sensor readings)\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "✅ **Fast experimentation** - Get results in minutes  \n",
    "✅ **Best practices built-in** - Follows ML best practices automatically  \n",
    "✅ **Transparency** - Generates notebooks you can review and modify  \n",
    "✅ **Production-ready** - Models are registered and ready to deploy  \n",
    "\n",
    "### When to Use AutoML:\n",
    "\n",
    "- Quick proof-of-concept\n",
    "- Baseline models for comparison\n",
    "- When you need results fast\n",
    "- Learning ML best practices\n",
    "\n",
    "### When Not to Use AutoML:\n",
    "\n",
    "- Highly specialized models needed\n",
    "- Custom architectures required\n",
    "- Deep learning for images/text\n",
    "- Fine control over every step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing Data for AutoML <a id=\"data-prep\"></a>\n",
    "\n",
    "### Load and Explore the Data\n",
    "\n",
    "First, let's load our inspection data with sensor features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inspection_silver table with sensor features\n",
    "df = spark.table(f\"{CATALOG}.{SCHEMA}.inspection_silver\")\n",
    "\n",
    "print(f\"Total records: {df.count():,}\")\n",
    "print(f\"\\nSchema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Show sample\n",
    "df.limit(5).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Target Variable Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "defect_dist = (\n",
    "    df.groupBy(\"defect\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"defect\")\n",
    ")\n",
    "\n",
    "defect_dist.display()\n",
    "\n",
    "# Show percentage\n",
    "total = df.count()\n",
    "defect_dist.withColumn(\n",
    "    \"percentage\", \n",
    "    (col(\"count\") / total * 100).cast(\"decimal(5,2)\")\n",
    ").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Features\n",
    "\n",
    "Select relevant features for prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# We'll use sensor readings to predict defects\n",
    "ml_data = df.select(\n",
    "    \"defect\",  # Target variable\n",
    "    \"sensor_temperature\",\n",
    "    \"sensor_density\", \n",
    "    \"sensor_delay\",\n",
    "    \"sensor_rotation_speed\",\n",
    "    \"sensor_air_pressure\",\n",
    "    \"sensor_airflow_rate\",\n",
    "    \"sensor_rotation_speed_EMA_5\",  # Exponential moving average feature\n",
    "    \"device_id\",\n",
    "    \"factory_id\",\n",
    "    \"model_id\"\n",
    ").na.drop()  # Remove rows with nulls\n",
    "\n",
    "print(f\"Records after removing nulls: {ml_data.count():,}\")\n",
    "ml_data.limit(10).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Dataset Table\n",
    "\n",
    "AutoML works best with Delta tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared dataset for AutoML\n",
    "training_table = f\"{CATALOG}.{SCHEMA}.defect_prediction_training\"\n",
    "\n",
    "ml_data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(training_table)\n",
    "\n",
    "print(f\"✅ Training data saved to: {training_table}\")\n",
    "print(f\"   Total records: {ml_data.count():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running Classification with AutoML <a id=\"classification\"></a>\n",
    "\n",
    "### Option 1: Using the UI (Recommended for Beginners)\n",
    "\n",
    "1. Click **Machine Learning** in the left sidebar\n",
    "2. Click **AutoML** (or **Experiments** → **Create AutoML Experiment**)\n",
    "3. Configure the experiment:\n",
    "   - **Problem type**: Classification\n",
    "   - **Dataset**: Select `defect_prediction_training` table\n",
    "   - **Target column**: `defect`\n",
    "   - **Evaluation metric**: F1 Score (good for imbalanced classes)\n",
    "   - **Training framework**: LightGBM, XGBoost, sklearn (select all)\n",
    "   - **Timeout**: 30 minutes\n",
    "4. Click **Start AutoML**\n",
    "5. Wait for the experiment to complete\n",
    "\n",
    "AutoML will:\n",
    "- Try multiple algorithms\n",
    "- Tune hyperparameters\n",
    "- Generate a leaderboard\n",
    "- Create notebooks for each model\n",
    "\n",
    "---\n",
    "\n",
    "### Option 2: Using Python API\n",
    "\n",
    "You can also run AutoML programmatically:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import automl\n",
    "\n",
    "# Run AutoML classification\n",
    "summary = automl.classify(\n",
    "    dataset=training_table,\n",
    "    target_col=\"defect\",\n",
    "    primary_metric=\"f1\",\n",
    "    timeout_minutes=30,\n",
    "    exclude_cols=[\"device_id\"],  # Exclude ID columns from features\n",
    "    experiment_name=f\"/Users/{spark.sql('SELECT current_user()').collect()[0][0]}/automl_defect_prediction\"\n",
    ")\n",
    "\n",
    "print(f\"Best trial F1 Score: {summary.best_trial.metrics['val_f1_score']:.4f}\")\n",
    "print(f\"Best trial Run ID: {summary.best_trial.mlflow_run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reviewing Results <a id=\"results\"></a>\n",
    "\n",
    "### Understanding the Leaderboard\n",
    "\n",
    "After AutoML completes, you'll see a leaderboard with:\n",
    "\n",
    "- **Model type**: Algorithm used (XGBoost, LightGBM, Random Forest, etc.)\n",
    "- **F1 Score**: Harmonic mean of precision and recall\n",
    "- **Precision**: Accuracy of positive predictions\n",
    "- **Recall**: Coverage of actual positives\n",
    "- **Accuracy**: Overall correctness\n",
    "- **AUC**: Area under ROC curve\n",
    "\n",
    "### Key Metrics for Classification:\n",
    "\n",
    "**F1 Score**: Best for imbalanced datasets (we have more non-defects than defects)\n",
    "- Range: 0 to 1 (higher is better)\n",
    "- Balances precision and recall\n",
    "\n",
    "**Precision**: Of predicted defects, how many are actually defects?\n",
    "- High precision = fewer false alarms\n",
    "\n",
    "**Recall**: Of actual defects, how many did we catch?\n",
    "- High recall = catch more defects, but may have false alarms\n",
    "\n",
    "**AUC**: Model's ability to distinguish between classes\n",
    "- Range: 0.5 (random) to 1.0 (perfect)\n",
    "\n",
    "### Reviewing the Best Model:\n",
    "\n",
    "1. Click on the best model in the leaderboard\n",
    "2. Review the **Model notebook** generated by AutoML\n",
    "3. Check **Feature importance** - which features matter most?\n",
    "4. Review **Confusion matrix** - where does the model make mistakes?\n",
    "5. Check **ROC curve** and **PR curve**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Feature Importance (After AutoML Completes)\n",
    "\n",
    "If you ran AutoML via Python API, you can access the best model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After AutoML completes, access the generated notebooks\n",
    "# The best model notebook will show feature importance\n",
    "\n",
    "# Example of what you'll see:\n",
    "print(\"\"\"\n",
    "Top Features for Predicting Defects (typical results):\n",
    "1. sensor_temperature - High temps correlate with defects\n",
    "2. sensor_rotation_speed_EMA_5 - Smoothed rotation speed pattern\n",
    "3. sensor_delay - Operational delays indicate issues  \n",
    "4. sensor_density - Material density affects performance\n",
    "5. sensor_air_pressure - Low pressure indicates problems\n",
    "\n",
    "These features help the model predict which devices will have defects!\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the Model for Predictions <a id=\"using-model\"></a>\n",
    "\n",
    "### Register the Model\n",
    "\n",
    "1. In the AutoML UI, click on your best model\n",
    "2. Click **Register model**\n",
    "3. Choose a name: `iot_defect_predictor`\n",
    "4. Add description and tags\n",
    "5. Click **Register**\n",
    "\n",
    "### Make Predictions\n",
    "\n",
    "Once registered, you can use the model to predict on new data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load model and make predictions\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Get the latest model version (after you've registered it)\n",
    "model_name = \"iot_defect_predictor\"\n",
    "\n",
    "# This is an example - update with your actual model URI after registration\n",
    "# model_uri = f\"models:/{model_name}/Production\"\n",
    "\n",
    "# Load new data for prediction\n",
    "new_sensor_data = spark.table(f\"{CATALOG}.{SCHEMA}.sensor_bronze\").limit(100)\n",
    "\n",
    "# Make predictions (example - actual code depends on your registered model)\n",
    "# predictions = mlflow.pyfunc.load_model(model_uri).predict(new_sensor_data.toPandas())\n",
    "\n",
    "print(\"\"\"\n",
    "After registration, you can:\n",
    "1. Load the model using MLflow\n",
    "2. Apply it to new sensor data\n",
    "3. Predict which devices will have defects\n",
    "4. Take preventive action before failures occur\n",
    "\n",
    "Example use cases:\n",
    "- Real-time monitoring: Flag devices predicted to fail\n",
    "- Preventive maintenance: Schedule inspections for high-risk devices\n",
    "- Quality control: Identify problematic batches early\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Scoring with SQL\n",
    "\n",
    "You can also apply the model directly in SQL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model registration, create a SQL function\n",
    "# Example SQL for batch inference:\n",
    "\n",
    "sql_example = \"\"\"\n",
    "-- Register model as SQL function\n",
    "CREATE OR REPLACE FUNCTION predict_defect(\n",
    "    temperature DOUBLE,\n",
    "    density FLOAT,\n",
    "    delay FLOAT,\n",
    "    rotation_speed DOUBLE,\n",
    "    air_pressure FLOAT,\n",
    "    airflow_rate DOUBLE,\n",
    "    rotation_speed_ema DOUBLE\n",
    ")\n",
    "RETURNS DOUBLE\n",
    "RETURN SELECT ai_query(\n",
    "    'iot_defect_predictor',\n",
    "    temperature,\n",
    "    density,\n",
    "    delay,\n",
    "    rotation_speed,\n",
    "    air_pressure,\n",
    "    airflow_rate,\n",
    "    rotation_speed_ema\n",
    ");\n",
    "\n",
    "-- Use the function to score data\n",
    "SELECT \n",
    "    device_id,\n",
    "    timestamp,\n",
    "    temperature,\n",
    "    predict_defect(\n",
    "        sensor_temperature,\n",
    "        sensor_density, \n",
    "        sensor_delay,\n",
    "        sensor_rotation_speed,\n",
    "        sensor_air_pressure,\n",
    "        sensor_airflow_rate,\n",
    "        sensor_rotation_speed_EMA_5\n",
    "    ) as defect_probability\n",
    "FROM sensor_bronze\n",
    "WHERE timestamp > current_timestamp() - INTERVAL 1 DAY\n",
    "ORDER BY defect_probability DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "print(\"SQL Batch Scoring Example:\")\n",
    "print(sql_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression (predicting temperature)\n",
    "regression_data = spark.table(f\"{CATALOG}.{SCHEMA}.sensor_bronze\").select(\n",
    "    \"temperature\",  # Target variable\n",
    "    \"rotation_speed\",\n",
    "    \"air_pressure\", \n",
    "    \"delay\",\n",
    "    \"density\",\n",
    "    \"airflow_rate\",\n",
    "    \"factory_id\",\n",
    "    \"model_id\"\n",
    ").na.drop()\n",
    "\n",
    "# Save regression training data\n",
    "regression_table = f\"{CATALOG}.{SCHEMA}.temperature_prediction_training\"\n",
    "regression_data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(regression_table)\n",
    "\n",
    "print(f\"✅ Regression data saved to: {regression_table}\")\n",
    "print(f\"   Total records: {regression_data.count():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AutoML Regression\n",
    "\n",
    "**Using the UI:**\n",
    "1. Create new AutoML experiment\n",
    "2. Select **Regression** as problem type\n",
    "3. Choose `temperature_prediction_training` table\n",
    "4. Target column: `temperature`\n",
    "5. Metric: RMSE (Root Mean Squared Error)\n",
    "6. Start AutoML\n",
    "\n",
    "**Using Python API:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AutoML for regression\n",
    "summary_regression = automl.regress(\n",
    "    dataset=regression_table,\n",
    "    target_col=\"temperature\",\n",
    "    primary_metric=\"rmse\",\n",
    "    timeout_minutes=20,\n",
    "    experiment_name=f\"/Users/{spark.sql('SELECT current_user()').collect()[0][0]}/automl_temperature_prediction\"\n",
    ")\n",
    "\n",
    "print(f\"Best trial RMSE: {summary_regression.best_trial.metrics['val_rmse']:.4f}\")\n",
    "print(f\"Best trial R²: {summary_regression.best_trial.metrics.get('val_r2_score', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics Explained\n",
    "\n",
    "**RMSE (Root Mean Squared Error)**: \n",
    "- Average prediction error in the same units as target\n",
    "- Lower is better\n",
    "- Example: RMSE of 5.2 means predictions are off by ~5.2 degrees on average\n",
    "\n",
    "**R² Score**:\n",
    "- Percentage of variance explained by the model\n",
    "- Range: 0 to 1 (higher is better)\n",
    "- 0.8 = Model explains 80% of variance in temperature\n",
    "\n",
    "**MAE (Mean Absolute Error)**:\n",
    "- Average absolute difference between predicted and actual\n",
    "- More interpretable than RMSE\n",
    "\n",
    "### Use Cases for Temperature Prediction:\n",
    "\n",
    "- **Anomaly detection**: Flag when actual temps deviate from predictions\n",
    "- **Capacity planning**: Predict cooling needs\n",
    "- **Energy optimization**: Forecast temperature changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ **What is AutoML** - Automated machine learning workflow  \n",
    "✅ **Prepare data** - Select features and create training tables  \n",
    "✅ **Run classification** - Predict defects using sensor data  \n",
    "✅ **Review results** - Understand metrics and feature importance  \n",
    "✅ **Deploy models** - Register and use models for predictions  \n",
    "✅ **Run regression** - Predict continuous values like temperature  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **AutoML automates** data preprocessing, feature engineering, model selection, and tuning\n",
    "2. **Classification** predicts categories (defect/no defect)\n",
    "3. **Regression** predicts continuous values (temperature)\n",
    "4. **F1 Score** is best for imbalanced classification problems\n",
    "5. **Feature importance** shows which sensor readings matter most\n",
    "6. **Model registration** makes models available for production use\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "**Data Preparation:**\n",
    "- Remove nulls and outliers\n",
    "- Check target variable distribution\n",
    "- Exclude ID columns from features\n",
    "- Include domain-relevant features\n",
    "\n",
    "**Model Evaluation:**\n",
    "- Use appropriate metrics for your problem\n",
    "- Check confusion matrix for classification\n",
    "- Review feature importance\n",
    "- Validate on holdout data\n",
    "\n",
    "**Production Deployment:**\n",
    "- Register best models in MLflow\n",
    "- Monitor model performance over time\n",
    "- Retrain periodically with new data\n",
    "- Set up alerts for drift\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "**Preventive Maintenance:**\n",
    "- Predict equipment failures before they occur\n",
    "- Schedule maintenance proactively\n",
    "- Reduce downtime and repair costs\n",
    "\n",
    "**Quality Control:**\n",
    "- Identify defective products early\n",
    "- Improve manufacturing processes\n",
    "- Reduce waste and rework\n",
    "\n",
    "**Anomaly Detection:**\n",
    "- Flag unusual sensor patterns\n",
    "- Detect cyber-attacks or tampering\n",
    "- Ensure operational safety\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Review the generated model notebooks from AutoML\n",
    "- Register your best model to Model Registry\n",
    "- Create a dashboard showing predictions\n",
    "- Set up a scheduled job for batch scoring\n",
    "- Explore feature engineering to improve performance\n",
    "\n",
    "---\n",
    "\n",
    "**Additional Resources:**\n",
    "- [AutoML Documentation](https://docs.databricks.com/aws/en/machine-learning/automl/)\n",
    "- [MLflow Model Registry](https://docs.databricks.com/aws/en/mlflow/model-registry)\n",
    "- [Model Serving](https://docs.databricks.com/aws/en/machine-learning/model-serving/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a2924ff-0cbd-4f30-adbc-d6918d3d9eb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "4 AutoML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
