{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "704f5b3c-fe4d-409b-bd12-0c2edb63a554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Overview: Discovering and Exploring Data\n",
    "\n",
    "In this notebook, you'll learn how to discover and explore data assets in Databricks using:\n",
    "- **Catalog Explorer** - UI-based data discovery\n",
    "- **SQL commands** - Programmatic data exploration\n",
    "- **Entity Relationship Diagrams** - Understanding table relationships\n",
    "- **Table Insights** - Viewing usage patterns\n",
    "\n",
    "## Prerequisites\n",
    "Before starting, ensure you've run the setup notebook to create the IoT dataset with:\n",
    "- Dimension tables (`dim_factories`, `dim_models`, `dim_devices`)\n",
    "- Bronze tables (`sensor_bronze`, `inspection_bronze`)\n",
    "- Silver tables (`anomaly_detected`, `inspection_silver`)\n",
    "- Gold table (`inspection_gold`)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Discovering Data with Catalog Explorer](#catalog-explorer)\n",
    "2. [Exploring Database Objects](#database-objects)\n",
    "3. [Exploring Files in Volumes](#volumes)\n",
    "4. [Viewing Entity Relationships](#entity-relationships)\n",
    "5. [Understanding Table Insights](#table-insights)\n",
    "\n",
    "---\n",
    "\n",
    "Reference Documentation:\n",
    "- [Discover Data](https://docs.databricks.com/aws/en/discover/)\n",
    "- [Catalog Explorer](https://docs.databricks.com/aws/en/catalog-explorer/)\n",
    "- [Explore Storage and Files](https://docs.databricks.com/aws/en/discover/files)\n",
    "- [Explore Database Objects](https://docs.databricks.com/aws/en/discover/database-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3154c390-d09d-4968-8bb8-cacdd9e6c548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set your catalog and schema\n",
    "CATALOG = 'default'  # Change to your catalog name\n",
    "SCHEMA = 'db_crash_course'  # Change to match your setup\n",
    "\n",
    "print(f\"Using: {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c77433dd-414b-4965-90a5-dfca75c7dbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## 1. Discovering Data with Catalog Explorer <a id=\"catalog-explorer\"></a>\n",
    "\n",
    "**Catalog Explorer** is a UI tool for exploring and managing data assets. You can access it by clicking **Catalog** in the sidebar.\n",
    "\n",
    "### What You Can Do with Catalog Explorer:\n",
    "- **Find data assets** - Browse catalogs, schemas, tables, and volumes\n",
    "- **Preview data** - View sample data and schema details\n",
    "- **Manage Unity Catalog** - Create objects, manage permissions, view ownership\n",
    "- **AI-assisted discovery** - Use AI-generated comments and natural language queries\n",
    "\n",
    "### Exercise: Open Catalog Explorer\n",
    "1. Click the **Catalog** icon in the left sidebar\n",
    "2. Navigate to your catalog (e.g., `default`)\n",
    "3. Find your schema (e.g., `db_crash_course`)\n",
    "4. Explore the tables created during setup\n",
    "\n",
    "You should see:\n",
    "- **Dimension Tables**: `dim_factories`, `dim_models`, `dim_devices`\n",
    "- **Bronze Tables**: `sensor_bronze`, `inspection_bronze`\n",
    "- **Silver Tables**: `anomaly_detected`, `inspection_silver`\n",
    "- **Gold Table**: `inspection_gold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Database Objects <a id=\"database-objects\"></a>\n",
    "\n",
    "Now let's use SQL to programmatically explore our database objects. You can discover catalogs, schemas, tables, and their metadata using `SHOW` and `DESCRIBE` commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all tables in your schema\n",
    "spark.sql(f\"SHOW TABLES IN {CATALOG}.{SCHEMA}\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Table Schema\n",
    "\n",
    "Use `DESCRIBE TABLE` to see column names, data types, and comments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the sensor_bronze table\n",
    "spark.sql(f\"DESCRIBE TABLE {CATALOG}.{SCHEMA}.sensor_bronze\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Extended Table Information\n",
    "\n",
    "Use `DESCRIBE TABLE EXTENDED` to see detailed metadata including location, provider, and properties:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get extended information about the table\n",
    "spark.sql(f\"DESCRIBE TABLE EXTENDED {CATALOG}.{SCHEMA}.sensor_bronze\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Table History (Delta Lake Feature)\n",
    "\n",
    "Delta Lake maintains a transaction log. You can view the table's history of operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View table history (shows all operations: CREATE, WRITE, MERGE, etc.)\n",
    "spark.sql(f\"DESCRIBE HISTORY {CATALOG}.{SCHEMA}.sensor_bronze\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Sample Data\n",
    "\n",
    "Let's preview the data in our tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview dimension tables\n",
    "print(\"Factories:\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.dim_factories\").display()\n",
    "\n",
    "print(\"\\nModels:\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.dim_models\").display()\n",
    "\n",
    "print(\"\\nDevices (sample):\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.dim_devices\").limit(10).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview sensor readings\n",
    "print(\"Sample Sensor Readings:\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.sensor_bronze\").limit(10).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Files in Volumes <a id=\"volumes\"></a>\n",
    "\n",
    "Unity Catalog **Volumes** provide managed access to files in cloud object storage. Our setup created volumes for storing raw data files.\n",
    "\n",
    "### List Volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all volumes in the schema\n",
    "spark.sql(f\"SHOW VOLUMES IN {CATALOG}.{SCHEMA}\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe a Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details about a specific volume\n",
    "spark.sql(f\"DESCRIBE VOLUME {CATALOG}.{SCHEMA}.sensor_data\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Files in a Volume\n",
    "\n",
    "Use the `LIST` command or Databricks utilities to explore files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in sensor_data volume using SQL\n",
    "spark.sql(f\"LIST '/Volumes/{CATALOG}/{SCHEMA}/sensor_data/'\").display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in inspection_data volume using dbutils\n",
    "files = dbutils.fs.ls(f\"/Volumes/{CATALOG}/{SCHEMA}/inspection_data/\")\n",
    "for file in files:\n",
    "    print(f\"  {file.name} - {file.size:,} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Volumes in Catalog Explorer\n",
    "\n",
    "1. In Catalog Explorer, navigate to your schema\n",
    "2. Click on **Volumes** to expand the list\n",
    "3. Click on `sensor_data` volume\n",
    "4. In the **Details** tab, you can see:\n",
    "   - Volume type\n",
    "   - Storage location\n",
    "   - Owner information\n",
    "5. Browse the files within the volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Viewing Entity Relationships <a id=\"entity-relationships\"></a>\n",
    "\n",
    "Our IoT dataset uses a **star schema** with primary and foreign key relationships. Databricks Catalog Explorer can visualize these relationships using an **Entity Relationship Diagram (ERD)**.\n",
    "\n",
    "### Understanding Our Data Model\n",
    "\n",
    "**Dimension Tables (with PRIMARY KEYs):**\n",
    "- `dim_factories` - Factory reference data, PK(`factory_id`)\n",
    "- `dim_models` - Device model reference data, PK(`model_id`)\n",
    "- `dim_devices` - Device master data, PK(`device_id`), FK→factories, FK→models\n",
    "\n",
    "**Fact Tables (with FOREIGN KEYs):**\n",
    "- `sensor_bronze` - IoT sensor readings, FK→devices, FK→factories, FK→models\n",
    "- `inspection_bronze` - Inspection records, FK→devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Primary and Foreign Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show constraints on dim_devices table\n",
    "# This table has a PRIMARY KEY and two FOREIGN KEYs\n",
    "spark.sql(f\"\"\"\n",
    "    DESCRIBE TABLE EXTENDED {CATALOG}.{SCHEMA}.dim_devices\n",
    "\"\"\").filter(\"col_name LIKE '%Constraint%' OR col_name = 'Table Constraints'\").display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show constraints on sensor_bronze table\n",
    "# This table has FOREIGN KEYs to dimension tables\n",
    "spark.sql(f\"\"\"\n",
    "    DESCRIBE TABLE EXTENDED {CATALOG}.{SCHEMA}.sensor_bronze\n",
    "\"\"\").filter(\"col_name LIKE '%Constraint%' OR col_name = 'Table Constraints'\").display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: View the Entity Relationship Diagram\n",
    "\n",
    "**To view the ERD in Catalog Explorer:**\n",
    "\n",
    "1. Navigate to Catalog Explorer\n",
    "2. Select one of the tables with foreign keys (e.g., `sensor_bronze` or `dim_devices`)\n",
    "3. Click on the **Columns** tab\n",
    "4. Click **View relationships** button (top-right)\n",
    "5. The ERD will display showing:\n",
    "   - Primary key columns (with key icon)\n",
    "   - Foreign key relationships (with connecting lines)\n",
    "   - Related tables in your schema\n",
    "\n",
    "The ERD provides an intuitive visualization of how data entities connect, making it easy to understand the data model at a glance.\n",
    "\n",
    "**Reference:** [Entity Relationship Diagram Documentation](https://docs.databricks.com/aws/en/catalog-explorer/entity-relationship-diagram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query with Joins\n",
    "\n",
    "Since we have defined relationships, we can easily join across dimension and fact tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join sensor data with dimension tables to get enriched information\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    s.device_id,\n",
    "    f.factory_name,\n",
    "    f.region,\n",
    "    m.model_name,\n",
    "    m.model_category,\n",
    "    s.timestamp,\n",
    "    s.temperature,\n",
    "    s.rotation_speed,\n",
    "    s.air_pressure\n",
    "FROM {CATALOG}.{SCHEMA}.sensor_bronze s\n",
    "JOIN {CATALOG}.{SCHEMA}.dim_devices d ON s.device_id = d.device_id\n",
    "JOIN {CATALOG}.{SCHEMA}.dim_factories f ON s.factory_id = f.factory_id\n",
    "JOIN {CATALOG}.{SCHEMA}.dim_models m ON s.model_id = m.model_id\n",
    "ORDER BY s.timestamp DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding Table Insights <a id=\"table-insights\"></a>\n",
    "\n",
    "Unity Catalog tracks **table usage metadata** for the past 30 days. You can see:\n",
    "- **Frequent queries** - Most common queries accessing the table\n",
    "- **Top users** - Users who access the table most often\n",
    "- **Query patterns** - How the data is being used\n",
    "\n",
    "This helps you understand:\n",
    "- Which tables are most valuable\n",
    "- Who your data consumers are\n",
    "- How to optimize frequently-run queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: View Table Insights in Catalog Explorer\n",
    "\n",
    "**To view insights for a table:**\n",
    "\n",
    "1. Open Catalog Explorer\n",
    "2. Navigate to a table (e.g., `sensor_bronze`)\n",
    "3. Click on the **Insights** tab\n",
    "4. You'll see:\n",
    "   - **Frequent queries** section showing most-run queries on this table\n",
    "   - **Top users** section showing who accesses this table\n",
    "   - Query frequency over time\n",
    "\n",
    "**Note:** Since this is a new dataset, you may not see much activity yet. Table insights populate as the table is queried over time.\n",
    "\n",
    "**Reference:** [Table Insights Documentation](https://docs.databricks.com/aws/en/discover/table-insights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Exploration: Search for Tables\n",
    "\n",
    "Databricks provides powerful search capabilities:\n",
    "\n",
    "1. **Keyword Search**: Use the search bar at the top of Databricks to find tables by name\n",
    "2. **Semantic Search**: Search for concepts (e.g., \"sensor temperature\") to find relevant datasets\n",
    "3. **Column-level Search**: Search returns results based on table names, column names, and comments\n",
    "\n",
    "**Exercise:**\n",
    "1. Click the search bar at the top of the Databricks UI\n",
    "2. Search for \"sensor\" - you should see `sensor_bronze` and related tables\n",
    "3. Try searching for \"factory\" or \"inspection\"\n",
    "\n",
    "The search only returns tables you have permission to see and searches across:\n",
    "- Table names\n",
    "- Column names  \n",
    "- Table comments\n",
    "- Column comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "✅ **Discover data** using Catalog Explorer's UI-based tools  \n",
    "✅ **Explore database objects** programmatically with SQL commands (`SHOW`, `DESCRIBE`, `LIST`)  \n",
    "✅ **Work with Unity Catalog Volumes** to manage files in cloud storage  \n",
    "✅ **Visualize entity relationships** using ERDs to understand table schemas  \n",
    "✅ **View table insights** to understand data usage patterns  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Catalog Explorer** provides a unified UI for data discovery and governance\n",
    "2. **SQL commands** like `SHOW TABLES`, `DESCRIBE TABLE`, and `DESCRIBE HISTORY` enable programmatic exploration\n",
    "3. **Volumes** provide secure, managed access to files in cloud object storage\n",
    "4. **Entity Relationship Diagrams** visualize primary/foreign key relationships\n",
    "5. **Table Insights** show query patterns and usage metrics\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore the **Lakeflow Designer** notebook to build visual data transformation pipelines\n",
    "- Try **AutoML** to build predictive models on the IoT dataset\n",
    "- Create **Dashboards** to visualize sensor metrics\n",
    "\n",
    "---\n",
    "\n",
    "**Additional Resources:**\n",
    "- [Discover Data](https://docs.databricks.com/aws/en/discover/)\n",
    "- [Catalog Explorer](https://docs.databricks.com/aws/en/catalog-explorer/)\n",
    "- [Unity Catalog](https://docs.databricks.com/aws/en/data-governance/unity-catalog/)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1 Databricks Overview",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
